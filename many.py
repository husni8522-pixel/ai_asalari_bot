import os
import pickle
import faiss
import numpy as np
from dotenv import load_dotenv
from langdetect import detect
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    CommandHandler,
    ContextTypes,
    CallbackQueryHandler,
    filters
)
from openai import OpenAI
from docx import Document
from pypdf import PdfReader
from datetime import datetime

# ================== CONFIG ==================
DATA_DIR = "data"
INDEX_FILE = "index.faiss"
META_FILE = "meta.pkl"

CHUNK_SIZE = 1000
BATCH_SIZE = 32
TOP_K = 8
MAX_MEMORY = 5

# ================== LOAD ENV ==================
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
ADMIN_ID = int(os.getenv("ADMIN_ID", 0))

client = OpenAI(api_key=OPENAI_KEY)

# ================== MEMORY & LOG ==================
user_memory = {}      # user_id -> savollar
questions_log = []    # savollar logi
user_stats = set()    # user_id lar
chat_log = {}         # chat_id -> {"title": str, "type": str}

# ================== LANGUAGE ==================
def detect_lang(text):
    try:
        l = detect(text)
        if l.startswith("ru"):
            return "ru"
        if l.startswith("en"):
            return "en"
        return "uz"
    except:
        return "uz"

# ================== BASIC CHAT ==================
def basic_chat(text):
    t = text.lower()
    if any(w in t for w in ["salom", "assalomu", "hello", "hi", "Ğ¿Ñ€Ğ¸Ğ²ĞµÑ‚"]):
        return {
            "uz": "Assalomu alaykum ğŸ˜Š Savolingizni yozing.",
            "ru": "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ ğŸ˜Š Ğ—Ğ°Ğ´Ğ°Ğ¹Ñ‚Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ.",
            "en": "Hello ğŸ˜Š Ask your question."
        }
    return None

# ================== ASALARI ==================
ASALARI_WORDS = [
    # ===== UZBEKCHA =====
"ari","arilar","asal","asalarichilik","asalarichi","ari oilasi","qirolicha","ona ari","ishchi ari","erkak ari",
"matka","truten","ari uyasi","katta uya","kichik uya","koâ€˜p qavatli uya","boâ€˜linma uya","ramka","katak","sota","panjara",
"mumli asos","asali panjara","asal ajratgich","asal ekstraktori","asal pichogâ€˜i","asalarichi kiyimi","niqob","qoâ€˜lqop",
"tutatuvchi","dimar","medogonka","ari zahri","qirollik suti","perga","gulchang","propolis","mum","honeycomb",
"oziqlantirish","shakar","sirop","kandi","bahorgi oziqlantirish","kuzgi oziqlantirish","qandari","togâ€˜ ari","suvli ari",
"quyoshli ari","italyanari","karlik ari","kafkasari","rus ari","yevropeysari","karniyari","himalayari","afrikari",
"medonosari","yovvoyi ari","asl ari","oâ€˜zbek ari","qora ari","shakarli ari","oâ€˜rta yevropalik ari",
"davolash","profilaktika","dori","kimyoviy davolash","organik davolash","oksalat kislota","formik kislota","timol",
"kasalliklar","varroa","nosema","akarapidoz","amerikan chirishi","yevropa chirishi","virus","zamburugâ€˜",
"ari kasalligi","jarayonlar","buzilishni oldini olish","samaradorlik","honey harvest","swarm prevention","feeding syrup",
"nectar collection","pollen collection","queen marking","brood inspection","colony management","hive inspection",
"queen cage","honey frame","brood frame","wax frame","foundation sheet","cappings","supers","brood box","honey super",
"apiary","beekeeper journal","inspection report","nectar flow","honey flow","protein supplement","bee genetics",
"bee space","uncapping fork","honey gate","hive tool","bee brush","bee feeder","swarm trap","swarm box","nectar trap",
"pollination","queen rearing","artificial insemination","colony splitting","winter preparation","spring preparation",
"feeding candy","feeding syrup","feeding pollen","feeding protein","wax foundation replacement","frame rotation",
"queen introduction","drone management","varroa treatment","nosema treatment","american foulbrood treatment",
"european foulbrood treatment","wax moth treatment","hive ventilation","temperature control","humidity control",
"smoker management","medogonka cleaning","extractor maintenance","bee suit maintenance","gloves cleaning","veil cleaning",
"bee health check","disease prevention","pollen analysis","honey analysis","royal jelly harvesting","bee venom collection",
"bee venom extraction","propagation","queen selection","swarm capture","swarm relocation","colony boosting",
"bee identification","apiary mapping","hive numbering","hive labelling","inspection schedule","feed schedule",
"winter feeding","summer feeding","autumn feeding","spring feeding","nectar monitoring","pollen monitoring",
"beekeeping records","colony performance","honey production","wax production","propolis production","perga storage",
"honey storage","wax storage","hive hygiene","apiary hygiene","hive spacing","apiary layout","swarm behavior",
"bee behavior","foraging behavior","colony development","brood development","queen development","drone development",
"hive maintenance","frame repair","foundation repair","honey extraction","wax rendering","beekeeping equipment","apiary security",
# ===== RUSCHA =====
"Ğ¿Ñ‡ĞµĞ»Ğ°","Ğ¿Ñ‡Ñ‘Ğ»Ñ‹","Ğ¼Ñ‘Ğ´","Ğ¿Ñ‡ĞµĞ»Ğ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾","Ğ¿Ñ‡ĞµĞ»Ğ¾Ğ²Ğ¾Ğ´","Ğ¿Ñ‡ĞµĞ»Ğ¸Ğ½Ğ°Ñ ÑĞµĞ¼ÑŒÑ","Ğ¼Ğ°Ñ‚ĞºĞ°","Ñ‚Ñ€ÑƒÑ‚ĞµĞ½ÑŒ","Ñ€Ğ°Ğ±Ğ¾Ñ‡Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ÑƒĞ»Ğ¸Ğ¹",
"Ğ¼Ğ½Ğ¾Ğ³Ğ¾ĞºĞ¾Ñ€Ğ¿ÑƒÑĞ½Ñ‹Ğ¹ ÑƒĞ»ĞµĞ¹","Ñ€Ğ°Ğ¼ĞºĞ°","ÑĞ¾Ñ‚Ñ‹","Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ğ°","Ñ€Ğ°Ğ·Ğ´ĞµĞ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ°Ñ Ñ€ĞµÑˆÑ‘Ñ‚ĞºĞ°","Ğ¼ĞµĞ´Ğ¾Ğ³Ğ¾Ğ½ĞºĞ°","Ğ¿Ñ‡ĞµĞ»Ğ¸Ğ½Ğ°Ñ Ğ¾Ğ´ĞµĞ¶Ğ´Ğ°","Ğ¼Ğ°ÑĞºĞ°",
"Ğ¿ĞµÑ€Ñ‡Ğ°Ñ‚ĞºĞ¸","Ñ‚ÑƒÑ‚Ğ°Ñ‚ÑƒÑ‡Ğ¸Ğ¹","Ğ´Ñ‹Ğ¼Ğ°Ñ€ÑŒ","Ğ½Ğ¾Ğ¶ Ğ´Ğ»Ñ Ñ€Ğ°ÑĞ¿ĞµÑ‡Ğ°Ñ‚ĞºĞ¸","Ğ¿ĞµÑ€Ğ³Ğ°","Ğ³ÑƒĞ»Ñ‡Ğ°Ğ½","Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ğ»Ğ¸Ñ","Ğ²Ğ¾ÑĞº","Ğ¼Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğµ Ğ¼Ğ¾Ğ»Ğ¾Ñ‡ĞºĞ¾",
"ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ","ÑĞ°Ñ…Ğ°Ñ€","ÑĞ¸Ñ€Ğ¾Ğ¿","ĞºĞ¾Ñ€Ğ¼Ğ¾Ğ²Ğ°Ñ Ğ¿Ğ°ÑÑ‚Ğ°","Ğ²ĞµÑĞµĞ½Ğ½ÑÑ Ğ¿Ğ¾Ğ´ĞºĞ¾Ñ€Ğ¼ĞºĞ°","Ğ¾ÑĞµĞ½Ğ½ÑÑ Ğ¿Ğ¾Ğ´ĞºĞ¾Ñ€Ğ¼ĞºĞ°","Ğ´Ğ¸ĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°",
"Ğ¸Ñ‚Ğ°Ğ»ÑŒÑĞ½ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ĞºĞ°Ñ€Ğ»Ğ¸ĞºĞ¾Ğ²Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ĞºĞ°Ğ²ĞºĞ°Ğ·ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ñ€ÑƒÑÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ĞµĞ²Ñ€Ğ¾Ğ¿ĞµĞ¹ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ĞºĞ°Ñ€Ğ½Ğ¸Ğ¹ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°",
"Ğ³Ğ¸Ğ¼Ğ°Ğ»Ğ°Ğ¹ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ğ°Ñ„Ñ€Ğ¸ĞºĞ°Ğ½ÑĞºĞ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ğ¼ĞµĞ´Ğ¾Ğ½Ğ¾ÑĞ½Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ğ¼ĞµÑÑ‚Ğ½Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ñ‡Ñ‘Ñ€Ğ½Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","ÑĞ¾Ğ»Ğ½ĞµÑ‡Ğ½Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°","Ğ²Ğ¾Ğ´Ğ½Ğ°Ñ Ğ¿Ñ‡ĞµĞ»Ğ°",
"Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ","Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ°ĞºÑ‚Ğ¸ĞºĞ°","Ğ»ĞµĞºĞ°Ñ€ÑÑ‚Ğ²Ğ¾","Ñ…Ğ¸Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ","Ğ¾Ñ€Ğ³Ğ°Ğ½Ğ¸Ñ‡ĞµÑĞºĞ¾Ğµ Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ","Ğ¾ĞºÑĞ°Ğ»Ğ¾Ğ²Ğ°Ñ ĞºĞ¸ÑĞ»Ğ¾Ñ‚Ğ°","Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‡ĞµÑĞºĞ°Ñ ĞºĞ¸ÑĞ»Ğ¾Ñ‚Ğ°","Ñ‚Ğ¸Ğ¼Ğ¾Ğ»",
"Ğ±Ğ¾Ğ»ĞµĞ·Ğ½Ğ¸","Ğ²Ğ°Ñ€Ñ€Ğ¾Ğ°","Ğ½Ğ¾Ğ·ĞµĞ¼Ğ°","Ğ°ĞºĞ°Ñ€Ğ°Ğ¿Ğ¸Ğ´Ğ¾Ğ·","Ğ°Ğ¼ĞµÑ€Ğ¸ĞºĞ°Ğ½ÑĞºĞ¸Ğ¹ Ğ³Ğ½Ğ¸Ğ»ĞµÑ†","ĞµĞ²Ñ€Ğ¾Ğ¿ĞµĞ¹ÑĞºĞ¸Ğ¹ Ğ³Ğ½Ğ¸Ğ»ĞµÑ†","Ğ²Ğ¸Ñ€ÑƒÑ","Ğ³Ñ€Ğ¸Ğ±Ğ¾Ğº","Ğ¿Ñ€Ğ¾Ñ†ĞµÑÑ","ÑĞ±Ğ¾Ñ€ Ğ¼Ñ‘Ğ´Ğ°",
"Ğ¿Ñ€ĞµĞ´Ğ¾Ñ‚Ğ²Ñ€Ğ°Ñ‰ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾ĞµĞ½Ğ¸Ñ","ÑĞ¸Ñ€Ğ¾Ğ¿ Ğ´Ğ»Ñ ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ñ","ÑĞ±Ğ¾Ñ€ Ğ½ĞµĞºÑ‚Ğ°Ñ€Ğ°","ÑĞ±Ğ¾Ñ€ Ğ¿Ñ‹Ğ»ÑŒÑ†Ñ‹","Ğ¾Ñ‚Ğ¼ĞµÑ‚ĞºĞ° Ğ¼Ğ°Ñ‚ĞºĞ¸","Ğ¸Ğ½ÑĞ¿ĞµĞºÑ†Ğ¸Ñ Ñ€Ğ°ÑĞ¿Ğ»Ğ¾Ğ´Ğ°","ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ ÑĞµĞ¼ÑŒĞµĞ¹",
"Ğ¾ÑĞ¼Ğ¾Ñ‚Ñ€ ÑƒĞ»ÑŒÑ","ĞºĞ»ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ¼Ğ°Ñ‚ĞºĞ¸","Ñ€Ğ°Ğ¼ĞºĞ° Ñ Ğ¼ĞµĞ´Ğ¾Ğ¼","Ñ€Ğ°Ğ¼ĞºĞ° Ñ Ñ€Ğ°ÑĞ¿Ğ»Ğ¾Ğ´Ğ¾Ğ¼","Ñ€Ğ°Ğ¼ĞºĞ° Ñ Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ğ¾Ğ¹","Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ğ°","ÑÑƒĞ¿ĞµÑ€Ñ‹","ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ° Ñ Ñ€Ğ°ÑĞ¿Ğ»Ğ¾Ğ´Ğ¾Ğ¼",
"ÑÑƒĞ¿ĞµÑ€ Ñ Ğ¼ĞµĞ´Ğ¾Ğ¼","Ğ¿Ğ°ÑĞµĞºĞ°","Ğ¶ÑƒÑ€Ğ½Ğ°Ğ» Ğ¿Ñ‡ĞµĞ»Ğ¾Ğ²Ğ¾Ğ´Ğ°","Ğ¾Ñ‚Ñ‡ĞµÑ‚ Ğ¾Ğ± Ğ¸Ğ½ÑĞ¿ĞµĞºÑ†Ğ¸Ğ¸","Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ½ĞµĞºÑ‚Ğ°Ñ€Ğ°","Ğ¿Ğ¾Ñ‚Ğ¾Ğº Ğ¼ĞµĞ´Ğ°","Ğ¿Ñ€Ğ¾Ñ‚ĞµĞ¸Ğ½Ğ¾Ğ²Ğ°Ñ Ğ´Ğ¾Ğ±Ğ°Ğ²ĞºĞ°",
"Ğ³ĞµĞ½ĞµÑ‚Ğ¸ĞºĞ° Ğ¿Ñ‡Ñ‘Ğ»","Ğ¿Ñ€Ğ¾ÑÑ‚Ñ€Ğ°Ğ½ÑÑ‚Ğ²Ğ¾ Ğ¿Ñ‡ĞµĞ»","Ğ²Ğ¸Ğ»ĞºĞ° Ğ´Ğ»Ñ Ñ€Ğ°ÑĞ¿ĞµÑ‡Ğ°Ñ‚ĞºĞ¸","Ğ²Ğ¾Ñ€Ğ¾Ñ‚Ğ° Ğ´Ğ»Ñ Ğ¼ĞµĞ´Ğ°","Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞ¼ĞµĞ½Ñ‚ Ğ´Ğ»Ñ ÑƒĞ»ÑŒÑ","Ñ‰ĞµÑ‚ĞºĞ° Ğ´Ğ»Ñ Ğ¿Ñ‡ĞµĞ»","ĞºĞ¾Ñ€Ğ¼ÑƒÑˆĞºĞ° Ğ´Ğ»Ñ Ğ¿Ñ‡Ñ‘Ğ»",
"Ğ»Ğ¾Ğ²ÑƒÑˆĞºĞ° Ğ´Ğ»Ñ Ñ€Ğ¾Ñ","ĞºĞ¾Ñ€Ğ¾Ğ±ĞºĞ° Ğ´Ğ»Ñ Ñ€Ğ¾Ñ","Ğ»Ğ¾Ğ²ÑƒÑˆĞºĞ° Ğ´Ğ»Ñ Ğ½ĞµĞºÑ‚Ğ°Ñ€Ğ°","Ğ¾Ğ¿Ñ‹Ğ»ĞµĞ½Ğ¸Ğµ","Ñ€Ğ°Ğ·Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚Ğ¾Ğº","Ğ¸ÑĞºÑƒÑÑÑ‚Ğ²ĞµĞ½Ğ½Ğ¾Ğµ Ğ¾ÑĞµĞ¼ĞµĞ½ĞµĞ½Ğ¸Ğµ","Ğ´ĞµĞ»ĞµĞ½Ğ¸Ğµ ÑĞµĞ¼ÑŒĞ¸",
"Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğº Ğ·Ğ¸Ğ¼Ğµ","Ğ¿Ğ¾Ğ´Ğ³Ğ¾Ñ‚Ğ¾Ğ²ĞºĞ° Ğº Ğ²ĞµÑĞ½Ğµ","ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ°Ñ…Ğ°Ñ€Ğ¾Ğ¼","ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ ÑĞ¸Ñ€Ğ¾Ğ¿Ğ¾Ğ¼","ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ¿Ñ‹Ğ»ÑŒÑ†Ğ¾Ğ¹","ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ Ğ±ĞµĞ»ĞºĞ¾Ğ¼",
"Ğ·Ğ°Ğ¼ĞµĞ½Ğ° Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ñ‹","Ğ¿Ğ¾Ğ²Ğ¾Ñ€Ğ¾Ñ‚ Ñ€Ğ°Ğ¼ĞºĞ¸","Ğ²Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞºĞ¸","ÑƒĞ¿Ñ€Ğ°Ğ²Ğ»ĞµĞ½Ğ¸Ğµ Ñ‚Ñ€ÑƒÑ‚Ğ½ÑĞ¼Ğ¸","Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ°Ñ€Ñ€Ğ¾Ğ°","Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ½Ğ¾Ğ·ĞµĞ¼Ñ‹","Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ°Ğ¼ĞµÑ€Ğ¸ĞºĞ°Ğ½ÑĞºĞ¾Ğ³Ğ¾ Ğ³Ğ½Ğ¸Ğ»ÑŒÑ†Ğ°",
"Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ ĞµĞ²Ñ€Ğ¾Ğ¿ĞµĞ¹ÑĞºĞ¾Ğ³Ğ¾ Ğ³Ğ½Ğ¸Ğ»ÑŒÑ†Ğ°","Ğ»ĞµÑ‡ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ğ½Ğ¾Ğ¹ Ğ¼Ğ¾Ğ»Ğ¸","Ğ²ĞµĞ½Ñ‚Ğ¸Ğ»ÑÑ†Ğ¸Ñ ÑƒĞ»ÑŒÑ","ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ñ‚ĞµĞ¼Ğ¿ĞµÑ€Ğ°Ñ‚ÑƒÑ€Ñ‹","ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ²Ğ»Ğ°Ğ¶Ğ½Ğ¾ÑÑ‚Ğ¸","ÑƒÑ…Ğ¾Ğ´ Ğ·Ğ° Ğ´Ñ‹Ğ¼Ğ°Ñ€ĞµĞ¼",
"Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼ĞµĞ´Ğ¾Ğ³Ğ¾Ğ½ĞºĞ¸","Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ÑĞºÑÑ‚Ñ€Ğ°ĞºÑ‚Ğ¾Ñ€Ğ°","ÑƒÑ…Ğ¾Ğ´ Ğ·Ğ° ĞºĞ¾ÑÑ‚ÑĞ¼Ğ¾Ğ¼","Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¿ĞµÑ€Ñ‡Ğ°Ñ‚Ğ¾Ğº","Ñ‡Ğ¸ÑÑ‚ĞºĞ° Ğ¼Ğ°ÑĞºĞ¸","Ğ¿Ñ€Ğ¾Ğ²ĞµÑ€ĞºĞ° Ğ·Ğ´Ğ¾Ñ€Ğ¾Ğ²ÑŒÑ Ğ¿Ñ‡Ñ‘Ğ»",
"Ğ¿Ñ€Ğ¾Ñ„Ğ¸Ğ»Ğ°ĞºÑ‚Ğ¸ĞºĞ° Ğ·Ğ°Ğ±Ğ¾Ğ»ĞµĞ²Ğ°Ğ½Ğ¸Ğ¹","Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¿Ñ‹Ğ»ÑŒÑ†Ñ‹","Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ¼Ñ‘Ğ´Ğ°","ÑĞ±Ğ¾Ñ€ Ğ¼Ğ°Ñ‚Ğ¾Ñ‡Ğ½Ğ¾Ğ³Ğ¾ Ğ¼Ğ¾Ğ»Ğ¾Ñ‡ĞºĞ°","ÑĞ±Ğ¾Ñ€ Ğ¿Ñ‡ĞµĞ»Ğ¸Ğ½Ğ¾Ğ³Ğ¾ ÑĞ´Ğ°","ÑĞºÑÑ‚Ñ€Ğ°ĞºÑ†Ğ¸Ñ Ğ¿Ñ‡ĞµĞ»Ğ¸Ğ½Ğ¾Ğ³Ğ¾ ÑĞ´Ğ°",
"Ñ€Ğ°Ğ·Ğ¼Ğ½Ğ¾Ğ¶ĞµĞ½Ğ¸Ğµ","Ğ¾Ñ‚Ğ±Ğ¾Ñ€ Ğ¼Ğ°Ñ‚Ğ¾Ğº","Ğ¿Ğ¾Ğ¹Ğ¼Ğ°Ñ‚ÑŒ Ñ€Ğ¾Ğ¹","Ğ¿ĞµÑ€ĞµÑĞµĞ»ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ñ","ÑƒÑĞ¸Ğ»ĞµĞ½Ğ¸Ğµ ÑĞµĞ¼ÑŒĞ¸","Ğ¸Ğ´ĞµĞ½Ñ‚Ğ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ Ğ¿Ñ‡Ñ‘Ğ»","ĞºĞ°Ñ€Ñ‚Ğ° Ğ¿Ğ°ÑĞµĞºĞ¸",
"Ğ½ÑƒĞ¼ĞµÑ€Ğ°Ñ†Ğ¸Ñ ÑƒĞ»ÑŒĞµĞ²","Ğ¼Ğ°Ñ€ĞºĞ¸Ñ€Ğ¾Ğ²ĞºĞ° ÑƒĞ»ÑŒĞµĞ²","Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº Ğ¸Ğ½ÑĞ¿ĞµĞºÑ†Ğ¸Ğ¸","Ğ³Ñ€Ğ°Ñ„Ğ¸Ğº ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ñ","Ğ·Ğ¸Ğ¼Ğ½ĞµĞµ ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ","Ğ»ĞµÑ‚Ğ½ĞµĞµ ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ",
"Ğ¾ÑĞµĞ½Ğ½ĞµĞµ ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ","Ğ²ĞµÑĞµĞ½Ğ½ĞµĞµ ĞºĞ¾Ñ€Ğ¼Ğ»ĞµĞ½Ğ¸Ğµ","Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ½ĞµĞºÑ‚Ğ°Ñ€Ğ°","Ğ¼Ğ¾Ğ½Ğ¸Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ³ Ğ¿Ñ‹Ğ»ÑŒÑ†Ñ‹","Ğ·Ğ°Ğ¿Ğ¸ÑĞ¸ Ğ¿Ñ‡ĞµĞ»Ğ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ°","Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ ÑĞµĞ¼ÑŒĞ¸",
"Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¼Ñ‘Ğ´Ğ°","Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ²Ğ¾ÑĞºĞ°","Ğ¿Ñ€Ğ¾Ğ¸Ğ·Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ¾ Ğ¿Ñ€Ğ¾Ğ¿Ğ¾Ğ»Ğ¸ÑĞ°","Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¿ĞµÑ€Ğ³Ğ¸","Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ¼Ñ‘Ğ´Ğ°","Ñ…Ñ€Ğ°Ğ½ĞµĞ½Ğ¸Ğµ Ğ²Ğ¾ÑĞºĞ°",
"Ğ³Ğ¸Ğ³Ğ¸ĞµĞ½Ğ° ÑƒĞ»ÑŒÑ","Ğ³Ğ¸Ğ³Ğ¸ĞµĞ½Ğ° Ğ¿Ğ°ÑĞµĞºĞ¸","Ñ€Ğ°Ğ·Ğ¼ĞµÑ‰ĞµĞ½Ğ¸Ğµ ÑƒĞ»ÑŒĞµĞ²","Ğ¿Ğ»Ğ°Ğ½Ğ¸Ñ€Ğ¾Ğ²ĞºĞ° Ğ¿Ğ°ÑĞµĞºĞ¸","Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ñ€Ğ¾Ñ","Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ‡Ñ‘Ğ»",
"Ğ¿Ğ¾Ğ²ĞµĞ´ĞµĞ½Ğ¸Ğµ Ğ¿Ñ€Ğ¸ ÑĞ±Ğ¾Ñ€Ğµ Ğ½ĞµĞºÑ‚Ğ°Ñ€Ğ°","Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ ÑĞµĞ¼ÑŒĞ¸","Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ñ€Ğ°ÑĞ¿Ğ»Ğ¾Ğ´Ğ°","Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ğ¼Ğ°Ñ‚ĞºĞ¸","Ñ€Ğ°Ğ·Ğ²Ğ¸Ñ‚Ğ¸Ğµ Ñ‚Ñ€ÑƒÑ‚Ğ½ĞµĞ¹","Ğ¾Ğ±ÑĞ»ÑƒĞ¶Ğ¸Ğ²Ğ°Ğ½Ğ¸Ğµ ÑƒĞ»ÑŒÑ",
"Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚ Ñ€Ğ°Ğ¼ĞºĞ¸","Ñ€ĞµĞ¼Ğ¾Ğ½Ñ‚ Ğ²Ğ¾Ñ‰Ğ¸Ğ½Ñ‹","ÑĞ±Ğ¾Ñ€ Ğ¼Ñ‘Ğ´Ğ°","Ğ¿ĞµÑ€ĞµÑ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ° Ğ²Ğ¾ÑĞºĞ°","Ğ¾Ğ±Ğ¾Ñ€ÑƒĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ Ğ¿Ğ°ÑĞµĞºĞ¸","Ğ±ĞµĞ·Ğ¾Ğ¿Ğ°ÑĞ½Ğ¾ÑÑ‚ÑŒ Ğ¿Ğ°ÑĞµĞºĞ¸",
# ===== ENGLISH =====
"bee","bees","honey","beekeeping","beekeeper","bee colony","queen bee","worker bee","drone bee","hive","beehive","nucleus hive",
"langstroth hive","frames","honeycomb","wax foundation","queen excluder","beekeeper suit","veil","gloves","smoker",
"honey extractor","propolis","royal jelly","bee bread","pollen","wax","feeding","sugar","syrup","candy","spring feeding",
"autumn feeding","candy feeding","drone bee","queen rearing","artificial insemination","colony splitting","winter prep",
"spring prep","nectar collection","pollen collection","swarm prevention","swarm capture","swarm relocation","colony boosting",
"bee identification","apiary mapping","hive numbering","hive labelling","inspection schedule","feed schedule","winter feeding",
"summer feeding","autumn feeding","spring feeding","nectar monitoring","pollen monitoring","beekeeping records","colony performance",
"honey production","wax production","propolis production","perga storage","honey storage","wax storage","hive hygiene","apiary hygiene",
"hive spacing","apiary layout","swarm behavior","bee behavior","foraging behavior","colony development","brood development",
"queen development","drone development","hive maintenance","frame repair","foundation repair","honey extraction","wax rendering",
"beekeeping equipment","apiary security","varroa treatment","nosema treatment","american foulbrood treatment","european foulbrood treatment",
"wax moth treatment","hive ventilation","temperature control","humidity control","smoker maintenance","medogonka cleaning",
"extractor maintenance","bee suit maintenance","gloves cleaning","veil cleaning","bee health check","disease prevention",
"pollen analysis","honey analysis","royal jelly harvesting","bee venom collection","bee venom extraction","propagation",
"queen selection","colony inspection","honey frame","brood frame","wax frame","foundation sheet","cappings","supers","brood box",
"honey super","queen marking","bee brush","bee feeder","swarm trap","swarm box","nectar trap","pollination"
]

def is_asalari(text):
    return any(w in text.lower() for w in ASALARI_WORDS)

# ================== FILES ==================
def read_file(path):
    if path.endswith(".docx"):
        return "\n".join(p.text for p in Document(path).paragraphs)
    if path.endswith(".pdf"):
        return "\n".join(p.extract_text() for p in PdfReader(path).pages if p.extract_text())
    if path.endswith(".txt"):
        return open(path, encoding="utf-8", errors="ignore").read()
    return ""

def chunk_text(text):
    return [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]

# ================== INDEX ==================
def build_index():
    docs = []
    for f in os.listdir(DATA_DIR):
        if f.endswith((".pdf", ".docx", ".txt")):
            text = read_file(os.path.join(DATA_DIR, f))
            for c in chunk_text(text):
                if len(c.strip()) > 50 and is_asalari(c):
                    docs.append(c.strip())
    if not docs:
        return
    vectors = []
    for i in range(0, len(docs), BATCH_SIZE):
        r = client.embeddings.create(model="text-embedding-3-small", input=docs[i:i+BATCH_SIZE])
        vectors.extend([d.embedding for d in r.data])
    index = faiss.IndexFlatL2(len(vectors[0]))
    index.add(np.array(vectors).astype("float32"))
    faiss.write_index(index, INDEX_FILE)
    pickle.dump(docs, open(META_FILE, "wb"))

def search_docs(q):
    if not os.path.exists(INDEX_FILE):
        return []
    index = faiss.read_index(INDEX_FILE)
    texts = pickle.load(open(META_FILE, "rb"))
    emb = client.embeddings.create(model="text-embedding-3-small", input=[q]).data[0].embedding
    _, I = index.search(np.array([emb]).astype("float32"), TOP_K)
    return [texts[i] for i in I[0]]

# ================== AI ANSWER ==================
def ai_answer(uid, q):
    lang = detect_lang(q)
    basic = basic_chat(q)
    if basic:
        return basic[lang]

    if uid not in user_memory:
        user_memory[uid] = []

    if not is_asalari(q):
        return {
            "uz": "ğŸ Bu bot faqat asalarichilik uchun.",
            "ru": "ğŸ Ğ‘Ğ¾Ñ‚ Ñ‚Ğ¾Ğ»ÑŒĞºĞ¾ Ğ´Ğ»Ñ Ğ¿Ñ‡ĞµĞ»Ğ¾Ğ²Ğ¾Ğ´ÑÑ‚Ğ²Ğ°.",
            "en": "ğŸ This bot is for beekeeping only."
        }[lang]

    user_memory[uid].append(q)

    ctx = "\n".join(search_docs(q))
    if not ctx:
        return {
            "uz": "âŒ Maâ€™lumot topilmadi.",
            "ru": "âŒ Ğ˜Ğ½Ñ„Ğ¾Ñ€Ğ¼Ğ°Ñ†Ğ¸Ñ Ğ½Ğµ Ğ½Ğ°Ğ¹Ğ´ĞµĞ½Ğ°.",
            "en": "âŒ No information found."
        }[lang]

    r = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "system", "content": "You are an expert beekeeper."},
                  {"role": "user", "content": f"{ctx}\n\nSavol: {q}"}],
        temperature=0.3
    )
    return r.choices[0].message.content.strip()

# ================== BUTTON ==================
def reset_button():
    return InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ”„ Yangi savol", callback_data="reset")]])

# ================== LOG CHAT ==================
async def log_chat(update: Update):
    chat = update.effective_chat
    user_stats.add(update.effective_user.id)
    if chat.id not in chat_log:
        chat_log[chat.id] = {
            "title": chat.title or f"{update.effective_user.first_name}",
            "type": chat.type
        }

# ================== HANDLERS ==================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await log_chat(update)
    await update.message.reply_text(
        "ğŸ Asalarichilik AI botga xush kelibsiz!",
        reply_markup=reset_button()
    )

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await log_chat(update)
    uid = update.effective_user.id
    q = update.message.text.strip()
    questions_log.append(q)
    ans = ai_answer(uid, q)

    await update.message.reply_text(ans, reply_markup=reset_button())

    if ADMIN_ID:
        await context.bot.send_message(
            ADMIN_ID,
            f"ğŸ‘¤ USER ID: {uid}\nğŸ•’ {datetime.now()}\nâ“ Savol: {q}\nâœ… Javob: {ans}\n"
            f"ğŸ’¬ Chat: {chat_log[update.effective_chat.id]['title']} ({chat_log[update.effective_chat.id]['type']})"
        )

async def reset_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    uid = query.from_user.id
    user_memory.pop(uid, None)
    await query.answer()
    await query.message.reply_text(
        "âœ… Context tozalandi. Yangi savol berishingiz mumkin.",
        reply_markup=reset_button()
    )

# ================== ADMIN ==================
async def reindex(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id != ADMIN_ID:
        await update.message.reply_text("âŒ Sizda bu komandani ishlatish huquqi yoâ€˜q.")
        return
    await update.message.reply_text("â™»ï¸ Indeks yangilanmoqda...")
    build_index()
    await update.message.reply_text("âœ… Indeks tayyor")

async def stats(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id != ADMIN_ID:
        await update.message.reply_text("âŒ Sizda bu komandani ishlatish huquqi yoâ€˜q.")
        return
    chats = "\n".join([f"{v['title']} ({v['type']})" for v in chat_log.values()])
    await update.message.reply_text(
        f"ğŸ“Š Foydalanuvchilar: {len(user_stats)}\n"
        f"ğŸ“© Savollar: {len(questions_log)}\n"
        f"ğŸ’¬ Guruhlar/kanallar:\n{chats}"
    )

# ================== MAIN ==================
if __name__ == "__main__":
    if not os.path.exists(INDEX_FILE):
        build_index()

    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("reindex", reindex))
    app.add_handler(CommandHandler("stats", stats))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(CallbackQueryHandler(reset_callback, pattern="^reset$"))

    print("ğŸ BOT ISHGA TUSHDI")
    app.run_polling()
