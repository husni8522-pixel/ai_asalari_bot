import os
import pickle
import faiss
import numpy as np
from dotenv import load_dotenv
from langdetect import detect
from telegram import (
    Update,
    InlineKeyboardButton,
    InlineKeyboardMarkup
)
from telegram.ext import (
    ApplicationBuilder,
    MessageHandler,
    CommandHandler,
    ContextTypes,
    CallbackQueryHandler,
    filters
)
from openai import OpenAI
from docx import Document
from pypdf import PdfReader

# ================== CONFIG ==================
DATA_DIR = "data"
INDEX_FILE = "index.faiss"
META_FILE = "meta.pkl"

CHUNK_SIZE = 1000
BATCH_SIZE = 32
TOP_K = 8
MAX_MEMORY = 5

# ================== LOAD ENV ==================
load_dotenv()
BOT_TOKEN = os.getenv("TELEGRAM_TOKEN")
OPENAI_KEY = os.getenv("OPENAI_API_KEY")
ADMIN_ID = int(os.getenv("ADMIN_ID", 0))

client = OpenAI(api_key=OPENAI_KEY)

# ================== MEMORY ==================
user_memory = {}  # user_id -> savollar

# ================== LANGUAGE ==================
def detect_lang(text):
    try:
        l = detect(text)
        if l.startswith("ru"):
            return "ru"
        if l.startswith("en"):
            return "en"
        return "uz"
    except:
        return "uz"

# ================== BASIC CHAT ==================
def basic_chat(text):
    t = text.lower()
    if any(w in t for w in ["salom", "assalomu", "hello", "hi", "–ø—Ä–∏–≤–µ—Ç"]):
        return {
            "uz": "Assalomu alaykum üòä Savolingizni yozing.",
            "ru": "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ üòä –ó–∞–¥–∞–π—Ç–µ –≤–æ–ø—Ä–æ—Å.",
            "en": "Hello üòä Ask your question."
        }
    return None

# ================== ASALARI ==================
ASALARI_WORDS = [
    # ---------- ASOSIY ----------
"ari","arilar","asal","asalarichilik","asalarichi",
"–∞—Ä–∏","–∞—Ä–∏–ª–∞—Ä","–∞—Å–∞–ª","–∞—Å–∞–ª–∞—Ä–∏—á–∏–ª–∏–∫","–∞—Å–∞–ª–∞—Ä–∏—á–∏",
"bee","bees","honey","beekeeping","beekeeper",
"–ø—á–µ–ª–∞","–ø—á—ë–ª—ã","–º—ë–¥","–ø—á–µ–ª–æ–≤–æ–¥—Å—Ç–≤–æ","–ø—á–µ–ª–æ–≤–æ–¥",
# ---------- ARI TURLARI ----------
"qirolicha","ona ari","ishchi ari","erkak ari","ari oilasi",
"“õ–∏—Ä–æ–ª–∏—á–∞","–æ–Ω–∞ –∞—Ä–∏","–∏—à—á–∏ –∞—Ä–∏","—ç—Ä–∫–∞–∫ –∞—Ä–∏","–∞—Ä–∏ –æ–∏–ª–∞—Å–∏",
"queen bee","worker bee","drone bee","bee colony",
"–º–∞—Ç–∫–∞","—Ä–∞–±–æ—á–∞—è –ø—á–µ–ª–∞","—Ç—Ä—É—Ç–µ–Ω—å","–ø—á–µ–ª–∏–Ω–∞—è —Å–µ–º—å—è",
# ---------- UYALAR ----------
"ari uyasi","ari uyalari","katta uya","kichik uya","ko‚Äòp qavatli uya",
"dadan","langstroth","rut","nukleus","bo‚Äòlinma uya",
"–∞—Ä–∏ —É—è—Å–∏","–∫–∞—Ç—Ç–∞ —É—è","–∫–∏—á–∏–∫ —É—è","–∫—û–ø “õ–∞–≤–∞—Ç–ª–∏ —É—è",
"—É–ª–µ–π","–º–Ω–æ–≥–æ–∫–æ—Ä–ø—É—Å–Ω—ã–π —É–ª–µ–π","–ª–µ–∂–∞–∫","–¥–∞–¥–∞–Ω",
"hive","beehive","langstroth hive","dadant hive","nucleus hive",
# ---------- UYA QISMLARI ----------
"ramka","ramkalar","katak","sota","panjara",
"asos","mumli asos","asali panjara",
"—Ä–∞–º–∫–∞","—Ä–∞–º–∫–∏","—Å–æ—Ç—ã","–≤–æ—â–∏–Ω–∞","—Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—å–Ω–∞—è —Ä–µ—à—ë—Ç–∫–∞",
"frame","frames","honeycomb","wax foundation","queen excluder",
# ---------- JIHOZLAR ----------
"asalarichi kiyimi","niqob","qo‚Äòlqop","tutatuvchi",
"asal ajratgich","asal ekstraktori","asal pichog‚Äòi",
"–∞—Å–∞–ª–∞—Ä–∏—á–∏ –∫–∏–π–∏–º–∏","–Ω–∏“õ–æ–±","“õ—û–ª“õ–æ–ø","—Ç—É—Ç–∞—Ç—É–≤—á–∏",
"–¥—ã–º–∞—Ä—å","–º–µ–¥–æ–≥–æ–Ω–∫–∞","–Ω–æ–∂ –¥–ª—è —Ä–∞—Å–ø–µ—á–∞—Ç–∫–∏",
"beekeeper suit","veil","gloves","smoker","honey extractor",
# ---------- MAHSULOTLAR ----------
"asal","mum","propolis","perga","gulchang","qirollik suti","ari zahri",
"–∞—Å–∞–ª","–º—É–º","–ø—Ä–æ–ø–æ–ª–∏—Å","–ø–µ—Ä–≥–∞","–≥—É–ª—á–∞–Ω–≥","–º–∞—Ç–æ—á–Ω–æ–µ –º–æ–ª–æ—á–∫–æ",
"honey","wax","propolis","bee bread","pollen","royal jelly",
# ---------- KASALLIKLAR ----------
"varroa","nosema","akarapidoz","amerikan chirishi","yevropa chirishi",
"virus","zamburug‚Äò","ari kasalligi",
"–≤–∞—Ä—Ä–æ–∞","–Ω–æ–∑–µ–º–∞","–∞–∫–∞—Ä–∞–ø–∏–¥–æ–∑","–≥–Ω–∏–ª–µ—Ü","–≤–∏—Ä—É—Å","–≥—Ä–∏–±–æ–∫",
"varroa mite","nosema disease","american foulbrood","viral disease",
# ---------- DAVOLASH ----------
"davolash","profilaktika","dori","kimyoviy davolash","organik davolash",
"oksalat kislota","formik kislota","timol",
"–¥–∞–≤–æ–ª–∞—à","–ø—Ä–æ—Ñ–∏–ª–∞–∫—Ç–∏–∫–∞","–¥–æ—Ä–∏","—â–∞–≤–µ–ª–µ–≤–∞—è –∫–∏—Å–ª–æ—Ç–∞","—Ç–∏–º–æ–ª",
"treatment","prevention","medicine","oxalic acid","formic acid",
# ---------- OZIQALANTIRISH ----------
"oziqlantirish","shakar","sirop","kandi","bahorgi oziqlantirish",
"–æ–∑–∏“õ–ª–∞–Ω—Ç–∏—Ä–∏—à","—à–∞–∫–∞—Ä","—Å–∏—Ä–æ–ø","–∫–∞–Ω–¥–∏",
"feeding","sugar","syrup","candy",
]

def is_asalari(text):
    return any(w in text.lower() for w in ASALARI_WORDS)

# ================== FILES ==================
def read_file(path):
    if path.endswith(".docx"):
        return "\n".join(p.text for p in Document(path).paragraphs)
    if path.endswith(".pdf"):
        return "\n".join(p.extract_text() for p in PdfReader(path).pages if p.extract_text())
    if path.endswith(".txt"):
        return open(path, encoding="utf-8", errors="ignore").read()
    return ""

def chunk_text(text):
    return [text[i:i+CHUNK_SIZE] for i in range(0, len(text), CHUNK_SIZE)]

# ================== INDEX ==================
def build_index():
    docs = []
    for f in os.listdir(DATA_DIR):
        if f.endswith((".pdf", ".docx", ".txt")):
            text = read_file(os.path.join(DATA_DIR, f))
            for c in chunk_text(text):
                if len(c.strip()) > 50 and is_asalari(c):
                    docs.append(c.strip())
    if not docs:
        return

    vectors = []
    for i in range(0, len(docs), BATCH_SIZE):
        r = client.embeddings.create(model="text-embedding-3-small", input=docs[i:i+BATCH_SIZE])
        vectors.extend([d.embedding for d in r.data])

    index = faiss.IndexFlatL2(len(vectors[0]))
    index.add(np.array(vectors).astype("float32"))
    faiss.write_index(index, INDEX_FILE)
    pickle.dump(docs, open(META_FILE, "wb"))

def search_docs(q):
    if not os.path.exists(INDEX_FILE):
        return []
    index = faiss.read_index(INDEX_FILE)
    texts = pickle.load(open(META_FILE, "rb"))
    emb = client.embeddings.create(model="text-embedding-3-small", input=[q]).data[0].embedding
    _, I = index.search(np.array([emb]).astype("float32"), TOP_K)
    return [texts[i] for i in I[0]]

# ================== AI ANSWER ==================
def ai_answer(uid, q):
    lang = detect_lang(q)
    basic = basic_chat(q)
    if basic:
        return basic[lang]

    if uid in user_memory:
        # Agar oldingi savol bo‚Äòlsa, avvalgi konteksti ishlatilmaydi
        pass
    else:
        user_memory[uid] = []

    if not is_asalari(q):
        return {
            "uz": "üêù Bu bot faqat asalarichilik uchun.",
            "ru": "üêù –ë–æ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –ø—á–µ–ª–æ–≤–æ–¥—Å—Ç–≤–∞.",
            "en": "üêù This bot is for beekeeping only."
        }[lang]

    user_memory[uid].append(q)

    ctx = "\n".join(search_docs(q))
    if not ctx:
        return {
            "uz": "‚ùå Ma‚Äôlumot topilmadi.",
            "ru": "‚ùå –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –Ω–µ –Ω–∞–π–¥–µ–Ω–∞.",
            "en": "‚ùå No information found."
        }[lang]

    r = client.chat.completions.create(
        model="gpt-4.1-mini",
        messages=[{"role": "system", "content": "You are an expert beekeeper."},
                  {"role": "user", "content": f"{ctx}\n\nSavol: {q}"}],
        temperature=0.3
    )
    return r.choices[0].message.content.strip()

# ================== BUTTON ==================
def reset_button():
    return InlineKeyboardMarkup([[InlineKeyboardButton("üîÑ Yangi savol", callback_data="reset")]])

# ================== HANDLERS ==================
async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    await update.message.reply_text("üêù Asalarichilik AI botga xush kelibsiz!", reply_markup=reset_button())

async def handle_text(update: Update, context: ContextTypes.DEFAULT_TYPE):
    uid = update.effective_user.id
    q = update.message.text.strip()
    ans = ai_answer(uid, q)
    await update.message.reply_text(ans, reply_markup=reset_button())

async def reset_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    query = update.callback_query
    uid = query.from_user.id
    user_memory.pop(uid, None)
    await query.answer()
    await query.message.reply_text("‚úÖ Context tozalandi. Yangi savol berishingiz mumkin.", reply_markup=reset_button())

# ================== ADMIN REINDEX ==================
async def reindex(update: Update, context: ContextTypes.DEFAULT_TYPE):
    if update.effective_user.id != ADMIN_ID:
        await update.message.reply_text("‚ùå Sizda bu komandani ishlatish huquqi yo‚Äòq.")
        return
    await update.message.reply_text("‚ôªÔ∏è Indeks yangilanmoqda...")
    build_index()
    await update.message.reply_text("‚úÖ Indeks tayyor")

# ================== MAIN ==================
if __name__ == "__main__":
    if not os.path.exists(INDEX_FILE):
        build_index()

    app = ApplicationBuilder().token(BOT_TOKEN).build()
    app.add_handler(CommandHandler("start", start))
    app.add_handler(CommandHandler("reindex", reindex))
    app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_text))
    app.add_handler(CallbackQueryHandler(reset_callback, pattern="^reset$"))

    print("üêù BOT ISHGA TUSHDI")
    app.run_polling()
